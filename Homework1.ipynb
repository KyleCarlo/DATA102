{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA102 Homework 1: Web Scraping\n",
    "\n",
    "**Group Number**: 3\n",
    "**Members**:\n",
    "- Jose Maria Angelo Guerra\n",
    "- Kyle Carlo Lasala\n",
    "- Katrina Bianca Roco\n",
    "- Antonio Jose Maria Lorenzo\n",
    "- Josh Angelo Theodore Borro\n",
    "- Charles Joseph Hinolan\n",
    "\n",
    "**Section**: S11\n",
    "\n",
    "**Instructor**: Mr. Jude Michael Teves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "page = \"https://itch.io/games\"\n",
    "#contact is my personal email\n",
    "headers = {\"User-Agent\": \"EducationalScraper/1.0 (contact: hinolancj@gmail.com)\"}\n",
    "\n",
    "# Disallowed paths based on itch.io/robots.txt\n",
    "disallowed_paths = [\"/embed/\", \"/embed-upload/\", \"/search\", \"/checkout/\", \"/game/download/\", \"/bundle/download/\", \"/register-for-purchase/\", \"/email-feedback/\"]\n",
    "\n",
    "# Function to check if URL is allowed\n",
    "def is_allowed(url):\n",
    "    for path in disallowed_paths:\n",
    "        if path in url:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "url = f\"{page}\"\n",
    "if is_allowed(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    print(soup.prettify())\n",
    "    time.sleep(2)\n",
    "else:\n",
    "    print(f\"Skipping disallowed URL: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Browser Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.edge.service import Service #microsft edge, change to webdriver.chrome.service for chrome\n",
    "\n",
    "driver_path = \"C:/Users/Charles/Desktop/COLLEGE/DATA102/edgedriver_win64/msedgedriver.exe\" #edit your driver's path\n",
    "url = \"https://itch.io/games\" # edit me\n",
    "\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Edge(service=service)\n",
    "\n",
    "driver.get(url)\n",
    "print(driver.page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data to extract (for now):\n",
    "1. game id (class=game_cell has_cover)\n",
    "2. game title (class=game_title)\n",
    "3. game text (class=game_text)\n",
    "4. author (class=game_author)\n",
    "5. platform (class=game_platform)\n",
    "6. genre (class=game_genre)\n",
    "\n",
    "-------------- need to click on the game to get the following data below--------------\n",
    "\n",
    "7. rating\n",
    "8. tags\n",
    "9. average session (time)\n",
    "10. inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto scrolling algorithm \n",
    "#TODO: make it retreive 1000 games\n",
    "pause = 0.5\n",
    "lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(pause)\n",
    "    newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if newHeight == lastHeight:\n",
    "        break\n",
    "    lastHeight = newHeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2955066\n",
      "Incredibox - Sprunki\n",
      "N/A\n",
      "wolf_hal\n",
      "N/A\n"
     ]
    }
   ],
   "source": [
    "#retrieve games\n",
    "games = driver.find_elements(By.XPATH, \"//div[@class='game_cell has_cover']\")\n",
    "\n",
    "#create lists\n",
    "id_list = []\n",
    "title_list = []\n",
    "genre_list = []\n",
    "author_list = []\n",
    "text_list = []\n",
    "\n",
    "#extract game data\n",
    "#NOTE: some games do not have all the data, so we need to account for that by adding N/A if the data is not present in order for the lists to be the same length\n",
    "#TODO: probably a better way to do the conditions\n",
    "for game in games:\n",
    "    #all games are guaranteed to have a game_id\n",
    "    game_id = game.get_attribute(\"data-game_id\")\n",
    "    id_list.append(game_id)\n",
    "\n",
    "    title = game.find_elements(By.XPATH, \".//a[@class='title game_link']\")\n",
    "    genre = game.find_elements(By.XPATH, \".//div[@class='game_genre']\")\n",
    "    author = game.find_elements(By.XPATH, \".//div[@class='game_author']\")\n",
    "    text = game.find_elements(By.XPATH, \".//div[@class='game_text']\")\n",
    "\n",
    "    if title:\n",
    "        title_list.append(title[0].text)\n",
    "    else:\n",
    "        title_list.append(\"N/A\")\n",
    "\n",
    "    if genre:\n",
    "        genre_list.append(genre[0].text)\n",
    "    else:\n",
    "        genre_list.append(\"N/A\")\n",
    "\n",
    "    if author:\n",
    "        author_list.append(author[0].text)\n",
    "    else:\n",
    "        author_list.append(\"N/A\")\n",
    "\n",
    "    if text:\n",
    "        text_list.append(text[0].text)\n",
    "    else:\n",
    "        text_list.append(\"N/A\")\n",
    "    \n",
    "print(id_list[0])    \n",
    "print(title_list[0])\n",
    "print(genre_list[0])\n",
    "print(author_list[0]) \n",
    "print(text_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635465\n",
      "\"Voices Of The Void\" Pre-Alpha\n",
      "Simulation\n",
      "mrdrnose\n",
      "Gather unknown signals from deep, silent space\n"
     ]
    }
   ],
   "source": [
    "print(id_list[1])\n",
    "print(title_list[1])\n",
    "print(genre_list[1])\n",
    "print(author_list[1])\n",
    "print(text_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data into the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the DataFrame to CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
